{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11800759,
          "sourceType": "datasetVersion",
          "datasetId": 7410762
        }
      ],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Download and extract the dataset files\n",
        "!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n",
        "!wget https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-listings.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60aeLixp8oKS",
        "outputId": "39642904-428f-4584-a05f-7da3617a7005"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-14 17:59:03--  https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-images-small.tar\n",
            "Resolving amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)... 52.216.53.153, 3.5.29.73, 52.217.226.73, ...\n",
            "Connecting to amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)|52.216.53.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3253381120 (3.0G) [application/x-tar]\n",
            "Saving to: ‘abo-images-small.tar’\n",
            "\n",
            "abo-images-small.ta 100%[===================>]   3.03G  35.9MB/s    in 83s     \n",
            "\n",
            "2025-05-14 18:00:26 (37.4 MB/s) - ‘abo-images-small.tar’ saved [3253381120/3253381120]\n",
            "\n",
            "--2025-05-14 18:00:26--  https://amazon-berkeley-objects.s3.amazonaws.com/archives/abo-listings.tar\n",
            "Resolving amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)... 3.5.24.52, 16.182.104.153, 52.217.15.60, ...\n",
            "Connecting to amazon-berkeley-objects.s3.amazonaws.com (amazon-berkeley-objects.s3.amazonaws.com)|3.5.24.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87480320 (83M) [application/x-tar]\n",
            "Saving to: ‘abo-listings.tar’\n",
            "\n",
            "abo-listings.tar    100%[===================>]  83.43M  19.2MB/s    in 4.5s    \n",
            "\n",
            "2025-05-14 18:00:31 (18.5 MB/s) - ‘abo-listings.tar’ saved [87480320/87480320]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf abo-images-small.tar\n",
        "!tar -xf abo-listings.tar"
      ],
      "metadata": {
        "id": "_xfiixMv8q4W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d images/metadata/images.csv.gz"
      ],
      "metadata": {
        "id": "EZGscr7Q8ssR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft accelerate transformers datasets bitsandbytes"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T20:55:26.765410Z",
          "iopub.execute_input": "2025-05-13T20:55:26.765695Z",
          "iopub.status.idle": "2025-05-13T20:57:10.431259Z",
          "shell.execute_reply.started": "2025-05-13T20:55:26.765666Z",
          "shell.execute_reply": "2025-05-13T20:57:10.430170Z"
        },
        "id": "sn6jMi8U5uWJ",
        "outputId": "194d6b3a-0f65-4bb6-f430-de171db2f0e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.31.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForQuestionAnswering, Trainer, TrainingArguments\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "#from sklearn.model_selection import train_test_split\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "\n",
        "# === CONFIGURATION ===\n",
        "BASE_IMAGE_PATH = './images/small'  # Adjust this to match your images/small directory\n",
        "CSV_PATH = './dataset_0_fixed_simplified.csv'  # Path to your CSV file\n",
        "METADATA_PATH = './images/metadata/images.csv'  # Path to the metadata CSV\n",
        "\n",
        "# === ACCELERATOR INIT ===\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# === LOAD BLIP MODEL & PROCESSOR ===\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\", use_fast=True)\n",
        "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
        "\n",
        "# === LOAD YOUR CURATED CSV ===\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"Loaded custom dataset with {len(df)} entries.\")\n",
        "\n",
        "# Load image metadata to map image_id to file paths\n",
        "try:\n",
        "    metadata_df = pd.read_csv(METADATA_PATH)\n",
        "    print(f\"Loaded metadata with {len(metadata_df)} images.\")\n",
        "    # Create a mapping from image_id to path\n",
        "    image_id_to_path = {}\n",
        "    for _, row in metadata_df.iterrows():\n",
        "        if 'image_id' in row and 'path' in row:\n",
        "            image_id_to_path[row['image_id']] = row['path']\n",
        "except Exception as e:\n",
        "    print(f\"Error loading metadata: {e}\")\n",
        "    # Fallback: assume image_id directly maps to path\n",
        "    image_id_to_path = {}\n",
        "\n",
        "# Ensure proper types\n",
        "df['answer'] = df['answer'].fillna('unknown').astype(str)\n",
        "df['image_id'] = df['image_id'].astype(str)\n",
        "\n",
        "# === TRAIN-TEST SPLIT ===\n",
        "train_df = df #, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(f\"Train size: {len(train_df)}\")# | Test size: {len(test_df)}\")\n",
        "\n",
        "# === DEFINE CUSTOM DATASET ===\n",
        "class VQADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, processor, image_base_path, image_id_to_path=None):\n",
        "        self.df = df\n",
        "        self.processor = processor\n",
        "        self.image_base_path = image_base_path\n",
        "        self.image_id_to_path = image_id_to_path or {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        image_id = row['image_id']\n",
        "\n",
        "        # Try to find image path using metadata mapping\n",
        "        if image_id in self.image_id_to_path:\n",
        "            # Use the path from metadata\n",
        "            relative_path = self.image_id_to_path[image_id]\n",
        "            full_image_path = os.path.join(self.image_base_path, relative_path)\n",
        "        else:\n",
        "            # Fallback: Determine path based on image_id first two characters\n",
        "            # For example, if image_id is \"81iZlv3bjpL\", it would go in folder \"8\"\n",
        "            # Adjust this logic based on your actual naming convention\n",
        "            prefix = image_id[:2]\n",
        "            full_image_path = os.path.join(self.image_base_path, prefix, f\"{image_id}.jpg\")\n",
        "\n",
        "            # If not found, try alternative patterns\n",
        "            if not os.path.exists(full_image_path):\n",
        "                # Try looking in a folder matching the first two characters\n",
        "                prefix = image_id[:2]\n",
        "                full_image_path = os.path.join(self.image_base_path, prefix, f\"{image_id}.jpg\")\n",
        "\n",
        "            if not os.path.exists(full_image_path):\n",
        "                # Last resort: search for the image recursively (could be slow)\n",
        "                for root, _, files in os.walk(self.image_base_path):\n",
        "                    for file in files:\n",
        "                        if image_id in file:\n",
        "                            full_image_path = os.path.join(root, file)\n",
        "                            break\n",
        "\n",
        "        try:\n",
        "            image = Image.open(full_image_path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load {full_image_path} for image_id {image_id}: {e}\")\n",
        "            image = Image.new(\"RGB\", (224, 224), (0, 0, 0))  # Fallback image\n",
        "\n",
        "        encoding = self.processor(\n",
        "            images=image,\n",
        "            text=row['question'],\n",
        "            padding=\"max_length\",\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "\n",
        "        labels = self.processor.tokenizer(\n",
        "            row['answer'],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=32,\n",
        "            return_tensors=\"pt\"\n",
        "        )[\"input_ids\"]\n",
        "\n",
        "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "        encoding[\"labels\"] = labels.squeeze(0)\n",
        "        return encoding\n",
        "\n",
        "# Add verification functions here\n",
        "def verify_dataset_images(dataset, num_samples=5):\n",
        "    \"\"\"Verify that images are being loaded correctly by checking a few samples\"\"\"\n",
        "    print(\"\\n=== DATASET VERIFICATION ===\")\n",
        "    print(f\"Dataset contains {len(dataset)} samples\")\n",
        "\n",
        "    # Check a few random samples\n",
        "    import random\n",
        "    random.seed(42)  # For reproducibility\n",
        "    sample_indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        try:\n",
        "            # Get the original data row\n",
        "            row = dataset.df.iloc[idx]\n",
        "            print(f\"\\nSample {i+1}/{len(sample_indices)}:\")\n",
        "            print(f\"  Question: {row['question']}\")\n",
        "            print(f\"  Answer: {row['answer']}\")\n",
        "            print(f\"  Image ID: {row['image_id']}\")\n",
        "\n",
        "            # Try to get the processed item\n",
        "            item = dataset[idx]\n",
        "            if 'pixel_values' in item:\n",
        "                pixel_shape = item['pixel_values'].shape\n",
        "                print(f\"  Image loaded successfully with shape: {pixel_shape}\")\n",
        "            else:\n",
        "                print(\"  Warning: No pixel_values in processed item\")\n",
        "\n",
        "            if 'input_ids' in item:\n",
        "                input_length = item['input_ids'].shape[0]\n",
        "                print(f\"  Question tokenized to {input_length} tokens\")\n",
        "            else:\n",
        "                print(\"  Warning: No input_ids in processed item\")\n",
        "\n",
        "            if 'labels' in item:\n",
        "                label_length = item['labels'].shape[0]\n",
        "                print(f\"  Answer tokenized to {label_length} tokens\")\n",
        "            else:\n",
        "                print(\"  Warning: No labels in processed item\")\n",
        "\n",
        "            print(\"  Sample loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing sample {idx}: {e}\")\n",
        "\n",
        "    print(\"\\n=== VERIFICATION COMPLETE ===\\n\")\n",
        "    return True\n",
        "\n",
        "# === CREATE DATASET INSTANCE ===\n",
        "train_dataset = VQADataset(train_df, processor, BASE_IMAGE_PATH, image_id_to_path)\n",
        "\n",
        "# Verify that the dataset is working properly\n",
        "verify_dataset_images(train_dataset)\n",
        "\n",
        "# === APPLY LoRA TO MODEL ===\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"LoRA applied.\")\n",
        "\n",
        "# === PREPARE MODEL FOR ACCELERATION ===\n",
        "model = accelerator.prepare(model)\n",
        "\n",
        "# === DEFINE TRAINING ARGUMENTS ===\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    run_name=\"blip_vqa_lora_finetune_curated\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# === DEFINE A VALIDATION CALLBACK ===\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class ValidationCallback(TrainerCallback):\n",
        "    def __init__(self, processor, interval=500):\n",
        "        self.processor = processor\n",
        "        self.interval = interval\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step % self.interval == 0 and state.global_step > 0:\n",
        "            model = kwargs.get('model', None)\n",
        "            if model is None:\n",
        "                return\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                # Generate a prediction for a simple example\n",
        "                prompt = \"What color is the object in the image?\"\n",
        "                inputs = processor(images=Image.new(\"RGB\", (224, 224), (100, 150, 200)),\n",
        "                                  text=prompt, return_tensors=\"pt\")\n",
        "                inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "                # Generate output\n",
        "                generated_ids = model.generate(**inputs, max_length=20)\n",
        "                generated_text = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "                print(f\"\\n=== VALIDATION AT STEP {state.global_step} ===\")\n",
        "                print(f\"Q: {prompt}\")\n",
        "                print(f\"A: {generated_text}\")\n",
        "                print(f\"Current training loss: {state.log_history[-1]['loss']:.4f}\")\n",
        "                print(f\"=== END VALIDATION ===\\n\")\n",
        "\n",
        "            model.train()\n",
        "\n",
        "# === TRAINER SETUP ===\n",
        "validation_callback = ValidationCallback(processor)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=default_data_collator,\n",
        "    callbacks=[validation_callback]\n",
        ")\n",
        "\n",
        "# === GPU INFO ===\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU GPU Memory Usage Before Training:\")\n",
        "    print(torch.cuda.memory_summary())\n",
        "\n",
        "# === START TRAINING ===\n",
        "trainer.train()\n",
        "\n",
        "# === SAVE MODEL ===\n",
        "trainer.save_model(\"./blip_vqa_lora_r_16\")\n",
        "print(\"Model saved to './blip_vqa_lora_r_16'\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T20:57:56.836690Z",
          "iopub.execute_input": "2025-05-13T20:57:56.837030Z",
          "iopub.status.idle": "2025-05-14T01:19:19.025006Z",
          "shell.execute_reply.started": "2025-05-13T20:57:56.836996Z",
          "shell.execute_reply": "2025-05-14T01:19:19.024219Z"
        },
        "id": "ZuNZ5g495uWL",
        "outputId": "28d7d930-48c7-42da-811b-5d6bbb7c2509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded custom dataset with 35184 entries.\n",
            "Loaded metadata with 398212 images.\n",
            "Train size: 35184\n",
            "\n",
            "=== DATASET VERIFICATION ===\n",
            "Dataset contains 35184 samples\n",
            "\n",
            "Sample 1/5:\n",
            "  Question: What is the primary component of the dish sauce?\n",
            "  Answer: Chicken\n",
            "  Image ID: 71ry7DlIvBL\n",
            "  Image loaded successfully with shape: torch.Size([3, 384, 384])\n",
            "  Question tokenized to 128 tokens\n",
            "  Answer tokenized to 32 tokens\n",
            "  Sample loaded successfully!\n",
            "\n",
            "Sample 2/5:\n",
            "  Question: What is the weight?\n",
            "  Answer: 13.2oz\n",
            "  Image ID: 81AGKphS3rL\n",
            "  Image loaded successfully with shape: torch.Size([3, 384, 384])\n",
            "  Question tokenized to 128 tokens\n",
            "  Answer tokenized to 32 tokens\n",
            "  Sample loaded successfully!\n",
            "\n",
            "Sample 3/5:\n",
            "  Question: Is it wireless?\n",
            "  Answer: Yes\n",
            "  Image ID: 81dfXp9sPZL\n",
            "  Image loaded successfully with shape: torch.Size([3, 384, 384])\n",
            "  Question tokenized to 128 tokens\n",
            "  Answer tokenized to 32 tokens\n",
            "  Sample loaded successfully!\n",
            "\n",
            "Sample 4/5:\n",
            "  Question: How many laundry detergent packs does this bag contain?\n",
            "  Answer: Thirtyfive\n",
            "  Image ID: 712tcklW2BL\n",
            "  Image loaded successfully with shape: torch.Size([3, 384, 384])\n",
            "  Question tokenized to 128 tokens\n",
            "  Answer tokenized to 32 tokens\n",
            "  Sample loaded successfully!\n",
            "\n",
            "Sample 5/5:\n",
            "  Question: Are these shoes lace-up?\n",
            "  Answer: Yes\n",
            "  Image ID: 81Egopgd8XL\n",
            "  Image loaded successfully with shape: torch.Size([3, 384, 384])\n",
            "  Question tokenized to 128 tokens\n",
            "  Answer tokenized to 32 tokens\n",
            "  Sample loaded successfully!\n",
            "\n",
            "=== VERIFICATION COMPLETE ===\n",
            "\n",
            "LoRA applied.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU GPU Memory Usage Before Training:\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   4565 MiB |   4565 MiB |  10999 GiB |  10995 GiB |\n",
            "|       from large pool |   4498 MiB |   4498 MiB |   9180 GiB |   9175 GiB |\n",
            "|       from small pool |     66 MiB |    206 MiB |   1819 GiB |   1819 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   4565 MiB |   4565 MiB |  10999 GiB |  10995 GiB |\n",
            "|       from large pool |   4498 MiB |   4498 MiB |   9180 GiB |   9175 GiB |\n",
            "|       from small pool |     66 MiB |    206 MiB |   1819 GiB |   1819 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |   4544 MiB |   4544 MiB |  10530 GiB |  10526 GiB |\n",
            "|       from large pool |   4477 MiB |   4477 MiB |   8711 GiB |   8706 GiB |\n",
            "|       from small pool |     66 MiB |    206 MiB |   1819 GiB |   1819 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   5052 MiB |   5052 MiB |   5052 MiB |      0 B   |\n",
            "|       from large pool |   4844 MiB |   4844 MiB |   4844 MiB |      0 B   |\n",
            "|       from small pool |    208 MiB |    208 MiB |    208 MiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 451185 KiB | 458713 KiB |   8349 GiB |   8348 GiB |\n",
            "|       from large pool | 353408 KiB | 360576 KiB |   6473 GiB |   6472 GiB |\n",
            "|       from small pool |  97777 KiB | 137251 KiB |   1876 GiB |   1875 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |    3580    |    3580    |    7244 K  |    7241 K  |\n",
            "|       from large pool |     907    |     907    |    1856 K  |    1855 K  |\n",
            "|       from small pool |    2673    |    2673    |    5388 K  |    5385 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |    3580    |    3580    |    7244 K  |    7241 K  |\n",
            "|       from large pool |     907    |     907    |    1856 K  |    1855 K  |\n",
            "|       from small pool |    2673    |    2673    |    5388 K  |    5385 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     313    |     313    |     313    |       0    |\n",
            "|       from large pool |     209    |     209    |     209    |       0    |\n",
            "|       from small pool |     104    |     104    |     104    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     320    |     320    |    4332 K  |    4332 K  |\n",
            "|       from large pool |     170    |     170    |    1303 K  |    1303 K  |\n",
            "|       from small pool |     150    |     200    |    3029 K  |    3029 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='116' max='6597' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 116/6597 01:57 < 1:51:35, 0.97 it/s, Epoch 0.05/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>10.322100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>10.162300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>9.903000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>9.751600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>9.565800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>9.482600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>9.373100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>9.207900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>9.107200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>9.040400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>8.984700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}
