# TradeLens: Optimizing Amazon Berkeley VQA


TradeLens is a computer vision model that leverages Low-Rank Adaptation (LoRA) fine-tuning to optimize Visual Question Answering performance on the Amazon Berkeley Objects dataset. The project focuses on creating a curated multiple-choice VQA dataset from product catalog images, establishing baseline performance using pre-trained multimodal models like BLIP-2, and then applying parameter-efficient LoRA fine-tuning to achieve superior accuracy and F1 scores.

By combining automated data curation through multimodal APIs, strategic model optimization, and comprehensive evaluation metrics, TradeLens optimizes visual understanding of e-commerce product catalogs while maintaining computational efficiency through constrained resource training on cloud GPUs.
